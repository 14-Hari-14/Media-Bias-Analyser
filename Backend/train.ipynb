{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-03-23T05:22:58.150746Z",
     "iopub.status.busy": "2025-03-23T05:22:58.150365Z",
     "iopub.status.idle": "2025-03-23T05:22:58.160834Z",
     "shell.execute_reply": "2025-03-23T05:22:58.159355Z",
     "shell.execute_reply.started": "2025-03-23T05:22:58.150709Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-23T04:57:34.635602Z",
     "iopub.status.busy": "2025-03-23T04:57:34.635207Z",
     "iopub.status.idle": "2025-03-23T04:57:53.259170Z",
     "shell.execute_reply": "2025-03-23T04:57:53.258525Z",
     "shell.execute_reply.started": "2025-03-23T04:57:34.635579Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import json\n",
    "import os\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "from torch.optim import AdamW\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-23T04:57:53.261591Z",
     "iopub.status.busy": "2025-03-23T04:57:53.261081Z",
     "iopub.status.idle": "2025-03-23T04:57:53.264779Z",
     "shell.execute_reply": "2025-03-23T04:57:53.263995Z",
     "shell.execute_reply.started": "2025-03-23T04:57:53.261564Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-23T04:57:53.266862Z",
     "iopub.status.busy": "2025-03-23T04:57:53.266451Z",
     "iopub.status.idle": "2025-03-23T04:57:53.294320Z",
     "shell.execute_reply": "2025-03-23T04:57:53.293560Z",
     "shell.execute_reply.started": "2025-03-23T04:57:53.266832Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class TextDataset(Dataset):\n",
    "    def __init__(self, texts, labels, tokenizer, max_length=128):\n",
    "        # Ensure texts are strings\n",
    "        texts = [str(text) for text in texts]\n",
    "        \n",
    "        # Tokenize inputs\n",
    "        self.encodings = tokenizer(\n",
    "            texts, \n",
    "            truncation=True, \n",
    "            padding=True, \n",
    "            max_length=max_length, \n",
    "            return_tensors='pt'\n",
    "        )\n",
    "        \n",
    "        # Encode labels\n",
    "        self.labels = torch.tensor(labels)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: val[idx] for key, val in self.encodings.items()}\n",
    "        item['labels'] = self.labels[idx]\n",
    "        return item\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-23T04:57:53.295343Z",
     "iopub.status.busy": "2025-03-23T04:57:53.295033Z",
     "iopub.status.idle": "2025-03-23T04:57:53.308391Z",
     "shell.execute_reply": "2025-03-23T04:57:53.307744Z",
     "shell.execute_reply.started": "2025-03-23T04:57:53.295323Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def get_tokens(text):\n",
    "    tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "    tokens = tokenizer.tokenize(text)\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-23T04:57:53.309311Z",
     "iopub.status.busy": "2025-03-23T04:57:53.309036Z",
     "iopub.status.idle": "2025-03-23T04:57:53.399461Z",
     "shell.execute_reply": "2025-03-23T04:57:53.398650Z",
     "shell.execute_reply.started": "2025-03-23T04:57:53.309292Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('/kaggle/input/media-bias/final_labels_SG2.csv',sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-23T04:57:53.400673Z",
     "iopub.status.busy": "2025-03-23T04:57:53.400393Z",
     "iopub.status.idle": "2025-03-23T04:57:53.426749Z",
     "shell.execute_reply": "2025-03-23T04:57:53.425776Z",
     "shell.execute_reply.started": "2025-03-23T04:57:53.400647Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "print(train_data.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-23T04:57:53.427912Z",
     "iopub.status.busy": "2025-03-23T04:57:53.427628Z",
     "iopub.status.idle": "2025-03-23T04:57:53.447967Z",
     "shell.execute_reply": "2025-03-23T04:57:53.447171Z",
     "shell.execute_reply.started": "2025-03-23T04:57:53.427889Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "columns = ['text', 'type']\n",
    "train_data = train_data[columns]\n",
    "train_data = train_data.dropna()\n",
    "print(train_data.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-23T04:57:53.450946Z",
     "iopub.status.busy": "2025-03-23T04:57:53.450749Z",
     "iopub.status.idle": "2025-03-23T04:57:53.457961Z",
     "shell.execute_reply": "2025-03-23T04:57:53.457316Z",
     "shell.execute_reply.started": "2025-03-23T04:57:53.450929Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "data = train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-23T04:57:53.459545Z",
     "iopub.status.busy": "2025-03-23T04:57:53.459358Z",
     "iopub.status.idle": "2025-03-23T04:57:53.469269Z",
     "shell.execute_reply": "2025-03-23T04:57:53.468602Z",
     "shell.execute_reply.started": "2025-03-23T04:57:53.459529Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "    \n",
    "X = data['text'].tolist()\n",
    "y = data['type'].tolist()\n",
    "X_train = X\n",
    "y_train = y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-23T04:57:53.470253Z",
     "iopub.status.busy": "2025-03-23T04:57:53.469994Z",
     "iopub.status.idle": "2025-03-23T04:57:53.506494Z",
     "shell.execute_reply": "2025-03-23T04:57:53.505670Z",
     "shell.execute_reply.started": "2025-03-23T04:57:53.470228Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "test_dataset = pd.read_csv('/kaggle/input/media-bias/final_labels_SG1.csv',sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-23T04:57:53.507513Z",
     "iopub.status.busy": "2025-03-23T04:57:53.507294Z",
     "iopub.status.idle": "2025-03-23T04:57:53.516777Z",
     "shell.execute_reply": "2025-03-23T04:57:53.515987Z",
     "shell.execute_reply.started": "2025-03-23T04:57:53.507495Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "columns = ['text', 'type']\n",
    "test_dataset= test_dataset[columns]\n",
    "test_dataset = test_dataset.dropna()\n",
    "print(test_dataset.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-23T04:57:53.517915Z",
     "iopub.status.busy": "2025-03-23T04:57:53.517679Z",
     "iopub.status.idle": "2025-03-23T04:57:53.528332Z",
     "shell.execute_reply": "2025-03-23T04:57:53.527656Z",
     "shell.execute_reply.started": "2025-03-23T04:57:53.517897Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "\n",
    "X_test = test_dataset['text'].tolist()\n",
    "y_test = test_dataset['type'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-23T04:57:53.529318Z",
     "iopub.status.busy": "2025-03-23T04:57:53.529015Z",
     "iopub.status.idle": "2025-03-23T04:57:53.541324Z",
     "shell.execute_reply": "2025-03-23T04:57:53.540655Z",
     "shell.execute_reply.started": "2025-03-23T04:57:53.529288Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "y_train_encoded = label_encoder.fit_transform(y_train)\n",
    "y_test_encoded = label_encoder.transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-23T05:01:40.357885Z",
     "iopub.status.busy": "2025-03-23T05:01:40.357592Z",
     "iopub.status.idle": "2025-03-23T05:01:44.489337Z",
     "shell.execute_reply": "2025-03-23T05:01:44.488400Z",
     "shell.execute_reply.started": "2025-03-23T05:01:40.357864Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Store the label mapping for later use during inference\n",
    "label_mapping = {i: label for i, label in enumerate(label_encoder.classes_)}\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "num_labels = len(label_encoder.classes_)\n",
    "\n",
    "train_dataset = TextDataset(X_train, y_train_encoded, tokenizer)\n",
    "test_dataset = TextDataset(X_test, y_test_encoded, tokenizer)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=50, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=50, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-23T05:01:44.490869Z",
     "iopub.status.busy": "2025-03-23T05:01:44.490562Z",
     "iopub.status.idle": "2025-03-23T05:01:49.078097Z",
     "shell.execute_reply": "2025-03-23T05:01:49.077235Z",
     "shell.execute_reply.started": "2025-03-23T05:01:44.490839Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "model = BertForSequenceClassification.from_pretrained(\n",
    "        'bert-base-uncased', \n",
    "        num_labels=num_labels\n",
    "    )\n",
    "if input(\"Load model from disk? (y/n): \").lower() == 'y':\n",
    "    model_path = os.getenv('MODEL_PATH')\n",
    "    model_conf = os.getenv('CONFIG_PATH')\n",
    "    print(f\"Loading model from path {model_path}\")\n",
    "    model.load_state_dict(torch.load(model_path))\n",
    "    with open(model_conf, 'r') as f:\n",
    "        config = json.load(f)\n",
    "        num_labels = config['num_labels']\n",
    "        label_mapping = config['label_mapping']\n",
    "else:\n",
    "    print(\"Training a new model\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-23T05:01:49.080292Z",
     "iopub.status.busy": "2025-03-23T05:01:49.080000Z",
     "iopub.status.idle": "2025-03-23T05:01:49.271269Z",
     "shell.execute_reply": "2025-03-23T05:01:49.270536Z",
     "shell.execute_reply.started": "2025-03-23T05:01:49.080272Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)\n",
    "    \n",
    "# Optimizer\n",
    "optimizer = AdamW(model.parameters(), lr=2e-4, weight_decay=2e-3)\n",
    "    \n",
    "# Training loop\n",
    "model.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-23T05:01:49.272580Z",
     "iopub.status.busy": "2025-03-23T05:01:49.272305Z",
     "iopub.status.idle": "2025-03-23T05:01:49.276156Z",
     "shell.execute_reply": "2025-03-23T05:01:49.275319Z",
     "shell.execute_reply.started": "2025-03-23T05:01:49.272560Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from torch.amp import GradScaler, autocast\n",
    "scaler = GradScaler('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-23T05:01:49.277346Z",
     "iopub.status.busy": "2025-03-23T05:01:49.277078Z",
     "iopub.status.idle": "2025-03-23T05:01:49.288485Z",
     "shell.execute_reply": "2025-03-23T05:01:49.287757Z",
     "shell.execute_reply.started": "2025-03-23T05:01:49.277327Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-23T05:01:49.289403Z",
     "iopub.status.busy": "2025-03-23T05:01:49.289175Z",
     "iopub.status.idle": "2025-03-23T05:01:49.300315Z",
     "shell.execute_reply": "2025-03-23T05:01:49.299601Z",
     "shell.execute_reply.started": "2025-03-23T05:01:49.289386Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "patience = 5\n",
    "min_delta = 0.001\n",
    "best_loss = float('inf')\n",
    "counter = 0\n",
    "early_stop = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-23T05:01:49.301232Z",
     "iopub.status.busy": "2025-03-23T05:01:49.300995Z",
     "iopub.status.idle": "2025-03-23T05:01:49.310903Z",
     "shell.execute_reply": "2025-03-23T05:01:49.310113Z",
     "shell.execute_reply.started": "2025-03-23T05:01:49.301179Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "if not os.path.exists('checkpoints'):\n",
    "    os.makedirs('checkpoints')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-23T05:04:46.647335Z",
     "iopub.status.busy": "2025-03-23T05:04:46.647007Z",
     "iopub.status.idle": "2025-03-23T05:14:12.518212Z",
     "shell.execute_reply": "2025-03-23T05:14:12.517477Z",
     "shell.execute_reply.started": "2025-03-23T05:04:46.647308Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "\n",
    "for epoch in range(20):\n",
    "    model.train()\n",
    "    print(f\"Epoch {epoch + 1}\")\n",
    "\n",
    "    running_loss = 0\n",
    "    num_batches = 0\n",
    "\n",
    "    for batch in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = torch.nn.functional.one_hot(batch['labels'].long(), num_classes=3).float().to(device)\n",
    "        \n",
    "        outputs = model(\n",
    "            input_ids, \n",
    "            attention_mask=attention_mask, \n",
    "            labels=labels\n",
    "        )\n",
    "        \n",
    "        loss = outputs.loss\n",
    "        loss.backward()\n",
    "\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "        \n",
    "        optimizer.step()\n",
    "        running_loss += loss\n",
    "        num_batches += 1\n",
    "        \n",
    "    print(f\"Average loss: {running_loss/num_batches} across {num_batches} batches\")\n",
    "\n",
    "    model.eval()\n",
    "    test_loss = 0.0\n",
    "    test_batches = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "            for test_batch in test_loader:\n",
    "                input_ids = test_batch['input_ids'].to(device)\n",
    "                attention_mask = test_batch['attention_mask'].to(device)\n",
    "                labels = torch.nn.functional.one_hot(test_batch['labels'].long(), num_classes=3).float().to(device)\n",
    "                \n",
    "                outputs = model(\n",
    "                    input_ids,\n",
    "                    attention_mask=attention_mask,\n",
    "                    labels=labels\n",
    "                )\n",
    "                \n",
    "                test_loss += outputs.loss.item()\n",
    "                test_batches += 1\n",
    "        \n",
    "    avg_test_loss = test_loss / test_batches\n",
    "    print(f\"Test Loss: {avg_test_loss:.4f}\")\n",
    "    \n",
    "    # Early stopping logic\n",
    "    if avg_test_loss < best_loss - min_delta:\n",
    "        # There is an improvement\n",
    "        best_loss = avg_test_loss\n",
    "        counter = 0\n",
    "        \n",
    "        # Save the best model\n",
    "        torch.save({\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'loss': best_loss,\n",
    "        }, f'checkpoints/best_model.pt')\n",
    "        print(f\"Model improved! Saved checkpoint at epoch {epoch + 1}\")\n",
    "    else:\n",
    "        # No improvement\n",
    "        counter += 1\n",
    "        print(f\"No improvement for {counter} epochs\")\n",
    "        \n",
    "        if counter >= patience:\n",
    "            early_stop = True\n",
    "            print(f\"No improvement after {patience} epochs. Stopping training.\")\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-23T05:14:20.616774Z",
     "iopub.status.busy": "2025-03-23T05:14:20.616499Z",
     "iopub.status.idle": "2025-03-23T05:14:21.658610Z",
     "shell.execute_reply": "2025-03-23T05:14:21.657739Z",
     "shell.execute_reply.started": "2025-03-23T05:14:20.616754Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "if os.path.exists('checkpoints/best_model.pt'):\n",
    "    checkpoint = torch.load('checkpoints/best_model.pt')\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    print(f\"Loaded best model from epoch {checkpoint['epoch'] + 1} with loss {checkpoint['loss']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-23T05:14:21.659855Z",
     "iopub.status.busy": "2025-03-23T05:14:21.659568Z",
     "iopub.status.idle": "2025-03-23T05:14:21.664368Z",
     "shell.execute_reply": "2025-03-23T05:14:21.663474Z",
     "shell.execute_reply.started": "2025-03-23T05:14:21.659828Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "model.eval()\n",
    "all_preds = []\n",
    "all_labels = []  \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-23T05:14:21.666005Z",
     "iopub.status.busy": "2025-03-23T05:14:21.665771Z",
     "iopub.status.idle": "2025-03-23T05:14:27.291651Z",
     "shell.execute_reply": "2025-03-23T05:14:27.290980Z",
     "shell.execute_reply.started": "2025-03-23T05:14:21.665986Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    for batch in test_loader:\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['labels'].to(device)\n",
    "        \n",
    "        outputs = model(\n",
    "            input_ids, \n",
    "            attention_mask=attention_mask\n",
    "        )\n",
    "        \n",
    "        preds = torch.argmax(outputs.logits, dim=1)\n",
    "        all_preds.extend(preds.cpu().numpy())\n",
    "        all_labels.extend(labels.cpu().numpy())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-23T05:14:27.292932Z",
     "iopub.status.busy": "2025-03-23T05:14:27.292632Z",
     "iopub.status.idle": "2025-03-23T05:14:27.303419Z",
     "shell.execute_reply": "2025-03-23T05:14:27.302501Z",
     "shell.execute_reply.started": "2025-03-23T05:14:27.292898Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score: 0.9883000968031171\n",
      "Accuracy: 0.9882352941176471\n"
     ]
    }
   ],
   "source": [
    "# Calculate F1 score\n",
    "f1 = f1_score(all_labels, all_preds, average='weighted')\n",
    "print(f\"F1 score: {f1}\")\n",
    "accuracy = sum([1 for i, j in zip(all_labels, all_preds) if i == j]) / len(all_labels)\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "\n",
    "# Save additional model metadata in a config file\n",
    "config = {\n",
    "    'num_labels': num_labels,\n",
    "    'label_mapping': label_mapping,\n",
    "    'f1_score': float(f1)\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-23T05:15:00.984910Z",
     "iopub.status.busy": "2025-03-23T05:15:00.984620Z",
     "iopub.status.idle": "2025-03-23T05:15:01.589531Z",
     "shell.execute_reply": "2025-03-23T05:15:01.588687Z",
     "shell.execute_reply.started": "2025-03-23T05:15:00.984891Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "if model is not None:\n",
    "    # Save with a fixed name instead of using F1 score in the filename\n",
    "    model_path = f'/kaggle/working/model_{float(config[\"f1_score\"]):.4f}.pt'\n",
    "    config_path = f'/kaggle/working/model_config_{float(config[\"f1_score\"]):.4f}.json'\n",
    "    \n",
    "    # Save the model\n",
    "    torch.save(model.state_dict(), model_path)\n",
    "    \n",
    "    # Save the config with label mapping\n",
    "    with open(config_path, 'w') as f:\n",
    "        json.dump(config, f)\n",
    "        \n",
    "    print(f\"Model saved to {model_path}\")\n",
    "    print(f\"Model config saved to {config_path}\")\n",
    "else:\n",
    "    print(\"No model to save\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 6818762,
     "sourceId": 10960367,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30920,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
